<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-L77KRD0B6Q"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-L77KRD0B6Q');
</script>




  
  <title>卡卡札记</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="卡卡札记">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="卡卡札记">
<meta property="og:locale">
<meta property="article:author" content="vincent leung">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/" title="卡卡札记" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.0.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <!-- <div id="banner"></div> -->
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">

      <h1 id="logo-wrap">
        <label id='logo'> 卡卡札记</label>

      </h1>
      <h2 >
        <label >技术-工具-生活</label>
      </h2>
    </div>
   
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
        <a id="nav-rss-link" class="nav-icon" href="/" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
        <a class="main-nav-link" href="/">Home</a>
        
        <a class="main-nav-link" href="/archives">Archives</a>
        
        <a class="main-nav-link" href="/contact-me">Contact</a>
        
        <a class="main-nav-link" href="/donate-me">Donate</a>
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-BERT_NER_CN_EN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/09/BERT_NER_CN_EN/" class="article-date">
  <time datetime="2020-09-09T08:45:15.045Z" itemprop="datePublished">2020-09-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/technology/">technology</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/09/BERT_NER_CN_EN/">基于BERT多语言的NER应用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="NER-命名实体识别-–-Named-entity-recognition"><a href="#NER-命名实体识别-–-Named-entity-recognition" class="headerlink" title="NER: 命名实体识别 – Named-entity recognition"></a>NER: 命名实体识别 – Named-entity recognition</h1><p>命名实体识别（Named Entity Recognition，简称NER），又称作“专名识别”，是指识别文本中具有特定意义的实体，主要包括__人名、地名、机构名、专有名词__等。简单的讲，就是识别自然文本中的__实体__和__类别__。</p>
<p>常用的NER算法很多， LSTM\HMM\CRF等一系列算法， 各自都可以获得不错的性能。</p>
<p>其实NER的本质就是分类算法（Classification），在BERT出现之前的各种算法和解决方案也够用， 为啥还需要弄个BERT的方案？</p>
<h1 id="基于BERT的NER-多语言混合方案"><a href="#基于BERT的NER-多语言混合方案" class="headerlink" title="基于BERT的NER 多语言混合方案"></a>基于BERT的NER 多语言混合方案</h1><p>采用BERT， 或者其他transformer类型的方案，单纯是因为其对于多语言的解决方案更有效更简单。而且可以和产品方案叠加使用（文章聚类， 摘要，关键词提取等等）。</p>
<p>下面先先介绍BERT的NER入门用法， 后续再介绍其训练和多语言混合， 以及更多拓展应用。</p>
<p>NER的类型不同方案有不同种类，这里主要关注以下几种:</p>
<blockquote>
<p>人名：PER,<br>地区：LOC,<br>组织：ORG</p>
</blockquote>
<p>如果一个实体名称分为几个token，一般使用<strong>B-</strong> 或者 <strong>I-</strong> 来区分开始和中间的token</p>
<p>比如：</p>
<p><strong>马一龙：PER</strong></p>
<blockquote>
<p>马：B-PER</p>
</blockquote>
<blockquote>
<p>一：I-PER</p>
</blockquote>
<blockquote>
<p>龙：I-PER</p>
</blockquote>
<h1 id="起手式：-去github找个项目"><a href="#起手式：-去github找个项目" class="headerlink" title="起手式： 去github找个项目"></a>起手式： 去github找个项目</h1><p>和其他Transformer模型一样, BERT三大步骤: Training, Fine-tune, Forward。其中train是不可能train的， 这辈子都没那么大的机器自己train， 我们还能做做的只有fine-tune和forward了。</p>
<p>Github上有大量的BERT NER方案， 现在随手去找一个参考参考： </p>
<p><a target="_blank" rel="noopener" href="https://github.com/kamalkraj/BERT-NER">BERT-NER</a>: 这个项目基本够用， 很多其他的项目也大同小异， 有些还用了CRF/LSTM的， 对比了一下性能差别不大， 毕竟各种classification算法都是90%左右的精度（__针对4种实体__），再高的精度一般有点训练过度（过拟合）。</p>
<p>该项目只支持英文， 有预训练的模型，可以直接下载使用。</p>
<p>但是我需要至少同时支持中英文， 所以只能自己微调（fine-tune）一个模型。</p>
<p>fine-tune的语料主要是经典的英文：<a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2003/ner/">CoNLL-2003</a>和中文：<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=52531">MSRA</a></p>
<h2 id="Fine-tune"><a href="#Fine-tune" class="headerlink" title="Fine-tune"></a>Fine-tune</h2><p>项目代码写的有点不合适中文使用， 我们改造一下接口</p>
<p>修改后的代码在github：<a href="">BERT_NER_CN_EN</a></p>
<h3 id="fine-tune数据"><a href="#fine-tune数据" class="headerlink" title="fine-tune数据"></a>fine-tune数据</h3><p>由于要支持中英文， 那只好把两种语言的语料结合一起， 下载来源参考<a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2003/ner/">CoNLL-2003</a>和中文：<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=52531">MSRA</a></p>
<p>下载后还需要把格式调整统一， 方便训练的时候输入。 具体格式为：</p>
<img src="/2020/09/09/BERT_NER_CN_EN/0.png" class="">


<p>格式说明： 一共两列数据， 第一列是token， 第二列是这个token的类型</p>
<p>token类型分为几类：<br>B-{PER|ORG|LOC|MISC}:这种B开头的token表明是某一种实体的开始token<br>I-{PER|ORG|LOC|MISC}:这种I开头的token表明是某一种实体的后续token， 开头的B token加上连续的I token构成一个完整的实体名称</p>
<ul>
<li><p>对于中文， 每个token就是一个汉字， 对于英文， 每个token就是一个单词</p>
</li>
<li><p>fine-tun数据规模：<br>简繁体的中文+英文+小部分日文， 约 500万个token</p>
</li>
</ul>
<p>训练数据和GitHub一起上传</p>
<h3 id="BERT-model"><a href="#BERT-model" class="headerlink" title="BERT model"></a>BERT model</h3><p>我们需要下载支持__多语言的BERT模型__， 这里选择普通的BERT Model即可。</p>
<p>另外， BERT模型有tf和pytorch格式， 相互之间需要转换才能使用。 嫌麻烦的可以直接去(transformers)[<a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers]">https://github.com/huggingface/transformers]</a> 下载。</p>
<ul>
<li>注：BERT nodel的 pytorch 文件和tf 2.0不一样， pytorch应该包含如图文件： <img src="/2020/09/09/BERT_NER_CN_EN/1.png" class="">




</li>
</ul>
<h3 id="run-ner-py"><a href="#run-ner-py" class="headerlink" title="run_ner.py"></a>run_ner.py</h3><p>当BERT模型和fine-tune数据都准备好后， 即可进行fine-tune训练。<br>这个是fine-tune的入口， 具体使用方法参考help信息， 主要说明如下:</p>
<ul>
<li><p>–data_dir<br>语料目录， 应该包含test， train， valid三个语料文件  </p>
</li>
<li><p>–bert_model<br>bert模型的路径</p>
</li>
<li><p>–task_name<br>固定为NER</p>
</li>
<li><p>–output_dir<br>输出模型的路径，其实就是经过微调之后的BERT模型</p>
</li>
</ul>
<h3 id="训练时间-（仅供参考）"><a href="#训练时间-（仅供参考）" class="headerlink" title="训练时间 （仅供参考）"></a>训练时间 （仅供参考）</h3><p>个人电脑 i7+RTX 2070显卡， 500万token， 3个full cycle， 需要差不多4个多小时。<br>这仅仅是fine-tune， 怪不得训练一个BERT要大几千美刀。</p>
<h2 id="Forward代码，-测试BERT实体识别"><a href="#Forward代码，-测试BERT实体识别" class="headerlink" title="Forward代码， 测试BERT实体识别"></a>Forward代码， 测试BERT实体识别</h2><p>先上代码： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertForTokenClassification,BertTokenizer</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">预训练的模型直接加载即可使用。</span></span><br><span class="line"><span class="string">模块核心函数: forward</span></span><br><span class="line"><span class="string">模块核心函数：predict</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertNer</span>(<span class="params">BertForTokenClassification</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    input_ids：句子的每个token对应的id数组</span></span><br><span class="line"><span class="string">    token type ids： 有时候写作segment ids， 用于区分token归属于哪一个句子，一般就1个或者2个句子，NER项目只会有1个句子</span></span><br><span class="line"><span class="string">    attention_mask: 略</span></span><br><span class="line"><span class="string">    valid_ids： 每个token是否mask token， 1对应原始token，0对应mask token。 对于每个token，可能是原始的token，也可以是mask之后的token，对于mask</span></span><br><span class="line"><span class="string">     比如有##符号的就是mask token</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     前三个参数都可以通过transformers的BertTokenizer获得，最后一个参数直接判断“##”符号即可</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input_ids, token_type_ids=None, attention_mask=None, valid_ids=None</span>):</span></span><br><span class="line">        sequence_output = self.bert(input_ids, token_type_ids, attention_mask, head_mask=<span class="literal">None</span>)[<span class="number">0</span>]</span><br><span class="line">        batch_size,max_len,feat_dim = sequence_output.shape</span><br><span class="line">        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32,device=<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">            jj = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(max_len):</span><br><span class="line">                    <span class="keyword">if</span> valid_ids[i][j].item() == <span class="number">1</span>:</span><br><span class="line">                        jj += <span class="number">1</span></span><br><span class="line">                        valid_output[i][jj] = sequence_output[i][j]</span><br><span class="line">        sequence_output = self.dropout(valid_output)</span><br><span class="line">        logits = self.classifier(sequence_output)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ner</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,model_dir: str</span>):</span></span><br><span class="line">        self.model , self.tokenizer, self.model_config = self.load_model(model_dir)</span><br><span class="line">        self.label_map = self.model_config[<span class="string">&quot;label_map&quot;</span>]</span><br><span class="line">        self.max_seq_length = self.model_config[<span class="string">&quot;max_seq_length&quot;</span>]</span><br><span class="line">        self.label_map = &#123;int(k):v <span class="keyword">for</span> k,v <span class="keyword">in</span> self.label_map.items()&#125;</span><br><span class="line">        self.device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">        self.model = self.model.to(self.device)</span><br><span class="line">        self.model.eval()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载模型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_model</span>(<span class="params">self, model_dir: str, model_config: str = <span class="string">&quot;model_config.json&quot;</span></span>):</span></span><br><span class="line">        model_config = os.path.join(model_dir,model_config)</span><br><span class="line">        model_config = json.load(open(model_config))</span><br><span class="line">        model = BertNer.from_pretrained(model_dir)</span><br><span class="line">        tokenizer = BertTokenizer.from_pretrained(model_dir, do_lower_case=model_config[<span class="string">&quot;do_lower&quot;</span>])</span><br><span class="line">        <span class="keyword">return</span> model, tokenizer, model_config</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;预处理函数</span></span><br><span class="line"><span class="string">    获得forward函数的4个参数，前三个直接获得</span></span><br><span class="line"><span class="string">    最后一个valid_pisitions遍历一次mask_words即可</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">self, text: str</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; preprocess &quot;&quot;&quot;</span></span><br><span class="line">        tks=self.tokenizer.encode_plus(text)</span><br><span class="line">        input_ids, token_type_ids, attention_mask=tks[<span class="string">&#x27;input_ids&#x27;</span>],tks[<span class="string">&#x27;token_type_ids&#x27;</span>],tks[<span class="string">&#x27;attention_mask&#x27;</span>]</span><br><span class="line">        self.mask_words=self.tokenizer.convert_ids_to_tokens(input_ids)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#words： 保存原始的token，去掉头尾[CLS][SEP]特殊标签</span></span><br><span class="line">        <span class="comment">#self.words=self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(input_ids)).split()</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#if len(self.words)&gt;2:</span></span><br><span class="line">        <span class="comment">#    self.words.pop()</span></span><br><span class="line">        <span class="comment">#    self.words.remove(&#x27;[CLS]&#x27;)</span></span><br><span class="line">            </span><br><span class="line">        self.words=[w <span class="keyword">for</span> w <span class="keyword">in</span> self.tokenizer.convert_ids_to_tokens(input_ids) <span class="keyword">if</span> <span class="string">&#x27;##&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> w <span class="keyword">and</span> w!=<span class="string">&#x27;[CLS]&#x27;</span> <span class="keyword">and</span> w!=<span class="string">&#x27;[SEP]&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        valid_positions=[ <span class="number">0</span> <span class="keyword">if</span> <span class="string">&#x27;##&#x27;</span> <span class="keyword">in</span> mw <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> mw <span class="keyword">in</span> self.mask_words]</span><br><span class="line">        <span class="keyword">while</span> len(input_ids) &lt; self.max_seq_length:</span><br><span class="line">            input_ids.append(<span class="number">0</span>)</span><br><span class="line">            token_type_ids.append(<span class="number">0</span>)</span><br><span class="line">            attention_mask.append(<span class="number">0</span>)</span><br><span class="line">            valid_positions.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> input_ids,token_type_ids,attention_mask,valid_positions</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    预测函数，输入句子， 输出NER结果</span></span><br><span class="line"><span class="string">    结果token是格式为: [&#123;&quot;word&quot;:word,&quot;tag&quot;:label,&quot;confidence&quot;:confidence&#125;]</span></span><br><span class="line"><span class="string">    其中，tag=&#x27;O&#x27;表示非实体，其他表示实体，B-开头表示实体开始，I-表示实体中间或结尾的token</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, text: str</span>):</span></span><br><span class="line">        </span><br><span class="line">        input_ids,segment_ids,attention_mask,valid_positions = self.preprocess(text)</span><br><span class="line">        input_ids = torch.tensor([input_ids],dtype=torch.long,device=self.device)</span><br><span class="line">        segment_ids = torch.tensor([segment_ids],dtype=torch.long,device=self.device)</span><br><span class="line">        attention_mask = torch.tensor([attention_mask],dtype=torch.long,device=self.device)</span><br><span class="line">        valid_positions = torch.tensor([valid_positions],dtype=torch.long,device=self.device)</span><br><span class="line">       <span class="comment"># print(&quot;test predict: &quot;,valid_positions)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这里model()函数实际上就是forward函数，求出classification的输出矩阵logits</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = self.model(input_ids, segment_ids, attention_mask,valid_positions)</span><br><span class="line">       </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这里进行softmax和argmax操作，把分类的标签（label）算出，作为最终的输出</span></span><br><span class="line">        logits = F.softmax(logits,dim=<span class="number">2</span>)</span><br><span class="line">        logits_label = torch.argmax(logits,dim=<span class="number">2</span>)</span><br><span class="line">        logits_label = logits_label.detach().cpu().numpy().tolist()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        logits_confidence = [values[label].item() <span class="keyword">for</span> values,label <span class="keyword">in</span> zip(logits[<span class="number">0</span>],logits_label)]</span><br><span class="line"></span><br><span class="line">        logits = []</span><br><span class="line">        pos = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index,mask <span class="keyword">in</span> enumerate(valid_positions[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> mask == <span class="number">1</span>:</span><br><span class="line">                logits.append((logits_label[index-pos],logits_confidence[index-pos]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pos += <span class="number">1</span></span><br><span class="line">        logits.pop()</span><br><span class="line"></span><br><span class="line">        labels = [(self.label_map[label],confidence) <span class="keyword">for</span> label,confidence <span class="keyword">in</span> logits]</span><br><span class="line">        words = self.words</span><br><span class="line">        <span class="comment">#print(&quot;labels：len：&quot;,labels,len(labels))</span></span><br><span class="line">        <span class="comment">#print(&quot;words: len: &quot;,words,len(words))</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> len(labels) == len(words)</span><br><span class="line">        output = [&#123;<span class="string">&quot;word&quot;</span>:word,<span class="string">&quot;tag&quot;</span>:label,<span class="string">&quot;confidence&quot;</span>:confidence&#125; <span class="keyword">for</span> word,(label,confidence) <span class="keyword">in</span> zip(words,labels)]</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h1><p>分三步：</p>
<ol>
<li>加载model</li>
<li>predict， 也就是传说中的forward</li>
<li>打印输出</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model_path=<span class="string">&#x27;C:/Users/vincent/Desktop/tools/BERT-NER/origin_multi_ner_result/&#x27;</span></span><br><span class="line"></span><br><span class="line">model = Ner(model_path)</span><br><span class="line"></span><br><span class="line">output = model.predict(<span class="string">&quot;在墨西哥城以北的一处在建机场的工地下，发现了200具古老的猛犸象骨骼。是有史以来规模最大的猛犸象骨骼化石遗迹。&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(output)</span><br></pre></td></tr></table></figure>

<pre><code>[&#123;&#39;word&#39;: &#39;在&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999240636825562&#125;, &#123;&#39;word&#39;: &#39;墨&#39;, &#39;tag&#39;: &#39;B-LOC&#39;, &#39;confidence&#39;: 0.9992677569389343&#125;, &#123;&#39;word&#39;: &#39;西&#39;, &#39;tag&#39;: &#39;I-LOC&#39;, &#39;confidence&#39;: 0.9996925592422485&#125;, &#123;&#39;word&#39;: &#39;哥&#39;, &#39;tag&#39;: &#39;I-LOC&#39;, &#39;confidence&#39;: 0.9996750354766846&#125;, &#123;&#39;word&#39;: &#39;城&#39;, &#39;tag&#39;: &#39;I-LOC&#39;, &#39;confidence&#39;: 0.9989588260650635&#125;, &#123;&#39;word&#39;: &#39;以&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9994268417358398&#125;, &#123;&#39;word&#39;: &#39;北&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9996019005775452&#125;, &#123;&#39;word&#39;: &#39;的&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.999887228012085&#125;, &#123;&#39;word&#39;: &#39;一&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.999910831451416&#125;, &#123;&#39;word&#39;: &#39;处&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998090863227844&#125;, &#123;&#39;word&#39;: &#39;在&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998877048492432&#125;, &#123;&#39;word&#39;: &#39;建&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9818888306617737&#125;, &#123;&#39;word&#39;: &#39;机&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9896661043167114&#125;, &#123;&#39;word&#39;: &#39;场&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9890062808990479&#125;, &#123;&#39;word&#39;: &#39;的&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.999804675579071&#125;, &#123;&#39;word&#39;: &#39;工&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9996554851531982&#125;, &#123;&#39;word&#39;: &#39;地&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9991917014122009&#125;, &#123;&#39;word&#39;: &#39;下&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9997368454933167&#125;, &#123;&#39;word&#39;: &#39;，&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998977184295654&#125;, &#123;&#39;word&#39;: &#39;发&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999265670776367&#125;, &#123;&#39;word&#39;: &#39;现&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998511075973511&#125;, &#123;&#39;word&#39;: &#39;了&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999287128448486&#125;, &#123;&#39;word&#39;: &#39;200&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.999941349029541&#125;, &#123;&#39;word&#39;: &#39;具&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999171495437622&#125;, &#123;&#39;word&#39;: &#39;古&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999344348907471&#125;, &#123;&#39;word&#39;: &#39;老&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999181032180786&#125;, &#123;&#39;word&#39;: &#39;的&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999264478683472&#125;, &#123;&#39;word&#39;: &#39;猛&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9980736970901489&#125;, &#123;&#39;word&#39;: &#39;[UNK]&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9985270500183105&#125;, &#123;&#39;word&#39;: &#39;象&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9993851184844971&#125;, &#123;&#39;word&#39;: &#39;骨&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998514652252197&#125;, &#123;&#39;word&#39;: &#39;骼&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998249411582947&#125;, &#123;&#39;word&#39;: &#39;。&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999047517776489&#125;, &#123;&#39;word&#39;: &#39;是&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999357461929321&#125;, &#123;&#39;word&#39;: &#39;有&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999390840530396&#125;, &#123;&#39;word&#39;: &#39;史&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999197721481323&#125;, &#123;&#39;word&#39;: &#39;以&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998682737350464&#125;, &#123;&#39;word&#39;: &#39;来&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999094009399414&#125;, &#123;&#39;word&#39;: &#39;规&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999364614486694&#125;, &#123;&#39;word&#39;: &#39;模&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999215602874756&#125;, &#123;&#39;word&#39;: &#39;最&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999353885650635&#125;, &#123;&#39;word&#39;: &#39;大&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999350309371948&#125;, &#123;&#39;word&#39;: &#39;的&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999313354492188&#125;, &#123;&#39;word&#39;: &#39;猛&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9977930784225464&#125;, &#123;&#39;word&#39;: &#39;[UNK]&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9983832836151123&#125;, &#123;&#39;word&#39;: &#39;象&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9988501071929932&#125;, &#123;&#39;word&#39;: &#39;骨&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.999836802482605&#125;, &#123;&#39;word&#39;: &#39;骼&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9997547268867493&#125;, &#123;&#39;word&#39;: &#39;化&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999040365219116&#125;, &#123;&#39;word&#39;: &#39;石&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998605251312256&#125;, &#123;&#39;word&#39;: &#39;遗&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9999046325683594&#125;, &#123;&#39;word&#39;: &#39;迹&#39;, &#39;tag&#39;: &#39;O&#39;, &#39;confidence&#39;: 0.9998475313186646&#125;, &#123;&#39;word&#39;: &#39;。&#39;, &#39;tag&#39;: &#39;[SEP]&#39;, &#39;confidence&#39;: 0.9971821308135986&#125;]</code></pre>
<h2 id="换一种展现方式："><a href="#换一种展现方式：" class="headerlink" title="换一种展现方式："></a>换一种展现方式：</h2><p><strong>针对不同的实体， 使用不同的展示方式</strong><br>目前有PER，LOC，ORG，MISC等几种，这里用不同的高亮颜色展示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HNER</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span> (<span class="params">self,output</span>):</span></span><br><span class="line">        self.html=self.display_ner(output,self.styles)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    styles=&#123;<span class="string">&quot;PER&quot;</span>:<span class="string">&quot;color:red;font-style:bold&quot;</span>,<span class="string">&quot;LOC&quot;</span>:<span class="string">&quot;color:green;font-style:bold&quot;</span>,<span class="string">&quot;ORG&quot;</span>:<span class="string">&quot;color:orange;font-style:bold&quot;</span>,</span><br><span class="line">            <span class="string">&quot;O&quot;</span>:<span class="string">&quot;color:black&quot;</span>,<span class="string">&quot;MISC&quot;</span>:<span class="string">&quot;color:purple;font-size:20&quot;</span>&#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">display_ner</span>(<span class="params">self,output,styles</span>):</span></span><br><span class="line">        html=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> output:</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> i[<span class="string">&#x27;tag&#x27;</span>] == <span class="string">&#x27;O&#x27;</span>:</span><br><span class="line">                s=styles[<span class="string">&#x27;O&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> i[<span class="string">&#x27;tag&#x27;</span>][<span class="number">2</span>:] <span class="keyword">in</span> styles.keys():</span><br><span class="line">                    s=styles[i[<span class="string">&#x27;tag&#x27;</span>][<span class="number">2</span>:]]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    s=<span class="string">&#x27;color:grey&#x27;</span></span><br><span class="line"></span><br><span class="line">            html+=<span class="string">&#x27;&lt;b style=&quot;&#123;1&#125;&quot;&gt; &#123;0&#125; &lt;/b&gt;&#x27;</span>.format(i[<span class="string">&#x27;word&#x27;</span>],s)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line">    </span><br><span class="line"> </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span>(<span class="params">text</span>):</span></span><br><span class="line">    pattern = <span class="string">r&#x27;[\?\t。\r\n？！；]&#x27;</span></span><br><span class="line">    sentences = [x <span class="keyword">for</span> x <span class="keyword">in</span> re.split(pattern, text.replace(<span class="string">r&#x27;[\r\n]&#x27;</span>,<span class="string">&#x27;&#x27;</span>)) <span class="keyword">if</span> len(x)&gt;<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> sentences</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text=<span class="string">&#x27;&#x27;&#x27;中山大学（简称：中大[注 4]；英语：Sun Yat-sen University，缩写为SYSU[注 5]）是一所中国大陆的综合性研究型大学，</span></span><br><span class="line"><span class="string">位于广东省广州市、珠海市和深圳市，直属于中华人民共和国教育部，由教育部与广东省人民政府共建。。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr_text=clean_text(text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> arr_text:</span><br><span class="line">    output=model.predict(t)</span><br><span class="line">    h+=HNER(output).html</span><br><span class="line">    </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TOSHOW</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span> (<span class="params">self,h</span>):</span></span><br><span class="line">        self.html=h</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_repr_html_</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.html</span><br><span class="line"></span><br><span class="line">TOSHOW(h)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<p><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> （ </b><b style="color:black"> 简 </b><b style="color:black"> 称 </b><b style="color:black"> ： </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:black"> [ </b><b style="color:black"> 注 </b><b style="color:black"> 4 </b><b style="color:black"> ] </b><b style="color:black"> 英 </b><b style="color:black"> 语 </b><b style="color:black"> ： </b><b style="color:orange;font-style:bold"> Sun </b><b style="color:orange;font-style:bold"> Ya </b><b style="color:orange;font-style:bold"> - </b><b style="color:orange;font-style:bold"> sen </b><b style="color:orange;font-style:bold"> University </b><b style="color:black"> ， </b><b style="color:black"> 缩 </b><b style="color:black"> 写 </b><b style="color:black"> 为 </b><b style="color:orange;font-style:bold"> S </b><b style="color:black"> [ </b><b style="color:black"> 注 </b><b style="color:black"> 5 </b><b style="color:black"> ] </b><b style="color:black"> ） </b><b style="color:black"> 是 </b><b style="color:black"> 一 </b><b style="color:black"> 所 </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 国 </b><b style="color:green;font-style:bold"> 大 </b><b style="color:green;font-style:bold"> 陆 </b><b style="color:black"> 的 </b><b style="color:black"> 综 </b><b style="color:black"> 合 </b><b style="color:black"> 性 </b><b style="color:black"> 研 </b><b style="color:black"> 究 </b><b style="color:black"> 型 </b><b style="color:black"> 大 </b><b style="color:black"> 学 </b><b style="color:black"> ， </b><b style="color:black"> 位 </b><b style="color:black"> 于 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 东 </b><b style="color:green;font-style:bold"> 省 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 州 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> 、 </b><b style="color:green;font-style:bold"> 珠 </b><b style="color:green;font-style:bold"> 海 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> 和 </b><b style="color:green;font-style:bold"> 深 </b><b style="color:green;font-style:bold"> 圳 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> ， </b><b style="color:black"> 直 </b><b style="color:black"> 属 </b><b style="color:black"> 于 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 华 </b><b style="color:orange;font-style:bold"> 人 </b><b style="color:orange;font-style:bold"> 民 </b><b style="color:orange;font-style:bold"> 共 </b><b style="color:orange;font-style:bold"> 和 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 教 </b><b style="color:orange;font-style:bold"> 育 </b><b style="color:orange;font-style:bold"> 部 </b><b style="color:black"> ， </b><b style="color:black"> 由 </b><b style="color:orange;font-style:bold"> 教 </b><b style="color:orange;font-style:bold"> 育 </b><b style="color:orange;font-style:bold"> 部 </b><b style="color:black"> 与 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 东 </b><b style="color:green;font-style:bold"> 省 </b><b style="color:orange;font-style:bold"> 人 </b><b style="color:orange;font-style:bold"> 民 </b><b style="color:black"> 政 </b><b style="color:black"> 府 </b><b style="color:black"> 共 </b><b style="color:black"> 建 </b></p>
<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p>从简单的测试结果可以看出，在句子混合中英文、简称、缩写的时候， BERT还是很轻松的识别出大部分实体。下面测试一些更复杂的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">text=<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">中山大学（简称：中大[注 4]；英语：Sun Yat-sen University，缩写为SYSU[注 5]）是一所中国大陆的综合性研究型大学，</span></span><br><span class="line"><span class="string">位于广东省广州市、珠海市和深圳市，直属于中华人民共和国教育部，由教育部与广东省人民政府共建</span></span><br><span class="line"><span class="string">该校前身为孙中山先生于1924年创立的国立广东大学，1926年为纪念创始人孙中山先生改称国立中山大学。</span></span><br><span class="line"><span class="string">1927年国民政府模仿法国“大学区”制度，在全国建立四所中央级“中山大学”，广州的国立中山大学改称为国立第一中山大学，</span></span><br><span class="line"><span class="string">1928年复名为国立中山大学。1950年，去除“国立”称谓仅称中山大学。</span></span><br><span class="line"><span class="string">1952年全国院系调整，原中山大学被拆分，众多院系被析出独立建校或并入他校，</span></span><br><span class="line"><span class="string">余下院系与私立岭南大学、华南联合大学等院校的部分院系合并重新组建中山大学，并将校址迁至原岭南大学的校园康乐园。</span></span><br><span class="line"><span class="string">2001年，中山大学与曾经析出的中山医科大学合并，成为现在的中山大学。</span></span><br><span class="line"><span class="string">另外，中华民国政府于1980年在台湾高雄西子湾复办国立中山大学。</span></span><br><span class="line"><span class="string">中山大學是中華人民共和國頂尖高校之一，是「一流大學建設A類高校」和原「985工程」、原「211工程」重點建設大學，</span></span><br><span class="line"><span class="string">具有人文社會科學、醫科和理工多學科厚實基礎，被譽爲「華南第一學府」。</span></span><br><span class="line"><span class="string">中山大學在2018年世界大學學術排名中，位列中國大陸第4-6名，世界第101-150名；</span></span><br><span class="line"><span class="string">在2019年QS世界大學排名、2019年泰晤士高等教育世界大學排名和2020年U.S.NEWS世界大學排名中，</span></span><br><span class="line"><span class="string">均位列中國大陸第8名，並分別位列世界第295名、301-350名與208名，近年排名提升迅猛</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">arr_text=clean_text(text)</span><br><span class="line">h=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> arr_text:</span><br><span class="line">    output=model.predict(t)</span><br><span class="line">    h+=HNER(output).html</span><br><span class="line">    </span><br><span class="line">dd=TOSHOW(h)</span><br><span class="line">dd</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<p><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> （ </b><b style="color:black"> 简 </b><b style="color:black"> 称 </b><b style="color:black"> ： </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:black"> [ </b><b style="color:black"> 注 </b><b style="color:black"> 4 </b><b style="color:black"> ] </b><b style="color:black"> 英 </b><b style="color:black"> 语 </b><b style="color:black"> ： </b><b style="color:orange;font-style:bold"> Sun </b><b style="color:orange;font-style:bold"> Ya </b><b style="color:orange;font-style:bold"> - </b><b style="color:orange;font-style:bold"> sen </b><b style="color:orange;font-style:bold"> University </b><b style="color:black"> ， </b><b style="color:black"> 缩 </b><b style="color:black"> 写 </b><b style="color:black"> 为 </b><b style="color:orange;font-style:bold"> S </b><b style="color:black"> [ </b><b style="color:black"> 注 </b><b style="color:black"> 5 </b><b style="color:black"> ] </b><b style="color:black"> ） </b><b style="color:black"> 是 </b><b style="color:black"> 一 </b><b style="color:black"> 所 </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 国 </b><b style="color:green;font-style:bold"> 大 </b><b style="color:green;font-style:bold"> 陆 </b><b style="color:black"> 的 </b><b style="color:black"> 综 </b><b style="color:black"> 合 </b><b style="color:black"> 性 </b><b style="color:black"> 研 </b><b style="color:black"> 究 </b><b style="color:black"> 型 </b><b style="color:black"> 大 </b><b style="color:black"> 学 </b><b style="color:black"> ， </b><b style="color:black"> 位 </b><b style="color:black"> 于 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 东 </b><b style="color:green;font-style:bold"> 省 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 州 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> 、 </b><b style="color:green;font-style:bold"> 珠 </b><b style="color:green;font-style:bold"> 海 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> 和 </b><b style="color:green;font-style:bold"> 深 </b><b style="color:green;font-style:bold"> 圳 </b><b style="color:green;font-style:bold"> 市 </b><b style="color:black"> ， </b><b style="color:black"> 直 </b><b style="color:black"> 属 </b><b style="color:black"> 于 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 华 </b><b style="color:orange;font-style:bold"> 人 </b><b style="color:orange;font-style:bold"> 民 </b><b style="color:orange;font-style:bold"> 共 </b><b style="color:orange;font-style:bold"> 和 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 教 </b><b style="color:orange;font-style:bold"> 育 </b><b style="color:orange;font-style:bold"> 部 </b><b style="color:black"> ， </b><b style="color:black"> 由 </b><b style="color:orange;font-style:bold"> 教 </b><b style="color:orange;font-style:bold"> 育 </b><b style="color:orange;font-style:bold"> 部 </b><b style="color:black"> 与 </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 东 </b><b style="color:green;font-style:bold"> 省 </b><b style="color:orange;font-style:bold"> 人 </b><b style="color:orange;font-style:bold"> 民 </b><b style="color:black"> 政 </b><b style="color:black"> 府 </b><b style="color:black"> 共 </b><b style="color:black"> 建 </b><b style="color:black"> 该 </b><b style="color:black"> 校 </b><b style="color:black"> 前 </b><b style="color:black"> 身 </b><b style="color:black"> 为 </b><b style="color:red;font-style:bold"> 孙 </b><b style="color:red;font-style:bold"> 中 </b><b style="color:red;font-style:bold"> 山 </b><b style="color:black"> 先 </b><b style="color:black"> 生 </b><b style="color:black"> 于 </b><b style="color:black"> 1924 </b><b style="color:black"> 年 </b><b style="color:black"> 创 </b><b style="color:black"> 立 </b><b style="color:black"> 的 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 广 </b><b style="color:orange;font-style:bold"> 东 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> ， </b><b style="color:black"> 1926 </b><b style="color:black"> 年 </b><b style="color:black"> 为 </b><b style="color:black"> 纪 </b><b style="color:black"> 念 </b><b style="color:black"> 创 </b><b style="color:black"> 始 </b><b style="color:black"> 人 </b><b style="color:red;font-style:bold"> 孙 </b><b style="color:red;font-style:bold"> 中 </b><b style="color:red;font-style:bold"> 山 </b><b style="color:black"> 先 </b><b style="color:black"> 生 </b><b style="color:black"> 改 </b><b style="color:black"> 称 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 1927 </b><b style="color:black"> 年 </b><b style="color:black"> 国 </b><b style="color:black"> 民 </b><b style="color:black"> 政 </b><b style="color:black"> 府 </b><b style="color:black"> 模 </b><b style="color:black"> 仿 </b><b style="color:green;font-style:bold"> 法 </b><b style="color:green;font-style:bold"> 国 </b><b style="color:black"> [UNK] </b><b style="color:black"> 大 </b><b style="color:black"> 学 </b><b style="color:black"> 区 </b><b style="color:black"> [UNK] </b><b style="color:black"> 制 </b><b style="color:black"> 度 </b><b style="color:black"> ， </b><b style="color:black"> 在 </b><b style="color:black"> 全 </b><b style="color:black"> 国 </b><b style="color:black"> 建 </b><b style="color:black"> 立 </b><b style="color:black"> 四 </b><b style="color:black"> 所 </b><b style="color:black"> 中 </b><b style="color:black"> 央 </b><b style="color:black"> 级 </b><b style="color:black"> [UNK] </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:black"> 学 </b><b style="color:black"> [UNK] </b><b style="color:black"> ， </b><b style="color:green;font-style:bold"> 广 </b><b style="color:green;font-style:bold"> 州 </b><b style="color:black"> 的 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 改 </b><b style="color:black"> 称 </b><b style="color:black"> 为 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 第 </b><b style="color:orange;font-style:bold"> 一 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> ， </b><b style="color:black"> 1928 </b><b style="color:black"> 年 </b><b style="color:black"> 复 </b><b style="color:black"> 名 </b><b style="color:black"> 为 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 1950 </b><b style="color:black"> 年 </b><b style="color:black"> ， </b><b style="color:black"> 去 </b><b style="color:black"> 除 </b><b style="color:black"> [UNK] </b><b style="color:black"> 国 </b><b style="color:black"> 立 </b><b style="color:black"> [UNK] </b><b style="color:black"> 称 </b><b style="color:black"> 谓 </b><b style="color:black"> 仅 </b><b style="color:black"> 称 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 1952 </b><b style="color:black"> 年 </b><b style="color:black"> 全 </b><b style="color:black"> 国 </b><b style="color:black"> 院 </b><b style="color:black"> 系 </b><b style="color:black"> 调 </b><b style="color:black"> 整 </b><b style="color:black"> ， </b><b style="color:black"> 原 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 被 </b><b style="color:black"> 拆 </b><b style="color:black"> 分 </b><b style="color:black"> ， </b><b style="color:black"> 众 </b><b style="color:black"> 多 </b><b style="color:black"> 院 </b><b style="color:black"> 系 </b><b style="color:black"> 被 </b><b style="color:black"> 析 </b><b style="color:black"> 出 </b><b style="color:black"> 独 </b><b style="color:black"> 立 </b><b style="color:black"> 建 </b><b style="color:black"> 校 </b><b style="color:black"> 或 </b><b style="color:black"> 并 </b><b style="color:black"> 入 </b><b style="color:black"> 他 </b><b style="color:black"> 校 </b><b style="color:black"> ， </b><b style="color:black"> 余 </b><b style="color:black"> 下 </b><b style="color:black"> 院 </b><b style="color:black"> 系 </b><b style="color:black"> 与 </b><b style="color:orange;font-style:bold"> 私 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 岭 </b><b style="color:orange;font-style:bold"> 南 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 、 </b><b style="color:orange;font-style:bold"> 华 </b><b style="color:orange;font-style:bold"> 南 </b><b style="color:orange;font-style:bold"> 联 </b><b style="color:orange;font-style:bold"> 合 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 等 </b><b style="color:black"> 院 </b><b style="color:black"> 校 </b><b style="color:black"> 的 </b><b style="color:black"> 部 </b><b style="color:black"> 分 </b><b style="color:black"> 院 </b><b style="color:black"> 系 </b><b style="color:black"> 合 </b><b style="color:black"> 并 </b><b style="color:black"> 重 </b><b style="color:black"> 新 </b><b style="color:black"> 组 </b><b style="color:black"> 建 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> ， </b><b style="color:black"> 并 </b><b style="color:black"> 将 </b><b style="color:black"> 校 </b><b style="color:black"> 址 </b><b style="color:black"> 迁 </b><b style="color:black"> 至 </b><b style="color:black"> 原 </b><b style="color:orange;font-style:bold"> 岭 </b><b style="color:orange;font-style:bold"> 南 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 的 </b><b style="color:black"> 校 </b><b style="color:black"> 园 </b><b style="color:green;font-style:bold"> 康 </b><b style="color:green;font-style:bold"> 乐 </b><b style="color:green;font-style:bold"> 园 </b><b style="color:black"> 2001 </b><b style="color:black"> 年 </b><b style="color:black"> ， </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 与 </b><b style="color:black"> 曾 </b><b style="color:black"> 经 </b><b style="color:black"> 析 </b><b style="color:black"> 出 </b><b style="color:black"> 的 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 医 </b><b style="color:orange;font-style:bold"> 科 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 合 </b><b style="color:black"> 并 </b><b style="color:black"> ， </b><b style="color:black"> 成 </b><b style="color:black"> 为 </b><b style="color:black"> 现 </b><b style="color:black"> 在 </b><b style="color:black"> 的 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:black"> 另 </b><b style="color:black"> 外 </b><b style="color:black"> ， </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 华 </b><b style="color:green;font-style:bold"> 民 </b><b style="color:green;font-style:bold"> 国 </b><b style="color:black"> 政 </b><b style="color:black"> 府 </b><b style="color:black"> 于 </b><b style="color:black"> 1980 </b><b style="color:black"> 年 </b><b style="color:black"> 在 </b><b style="color:green;font-style:bold"> 台 </b><b style="color:green;font-style:bold"> 湾 </b><b style="color:green;font-style:bold"> 高 </b><b style="color:green;font-style:bold"> 雄 </b><b style="color:green;font-style:bold"> 西 </b><b style="color:green;font-style:bold"> 子 </b><b style="color:green;font-style:bold"> 湾 </b><b style="color:black"> 复 </b><b style="color:black"> 办 </b><b style="color:orange;font-style:bold"> 国 </b><b style="color:orange;font-style:bold"> 立 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 学 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 學 </b><b style="color:black"> 是 </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 華 </b><b style="color:green;font-style:bold"> 人 </b><b style="color:green;font-style:bold"> 民 </b><b style="color:green;font-style:bold"> 共 </b><b style="color:green;font-style:bold"> 和 </b><b style="color:green;font-style:bold"> 國 </b><b style="color:black"> 頂 </b><b style="color:black"> 尖 </b><b style="color:black"> 高 </b><b style="color:black"> 校 </b><b style="color:black"> 之 </b><b style="color:black"> 一 </b><b style="color:black"> ， </b><b style="color:black"> 是 </b><b style="color:black"> 「 </b><b style="color:black"> 一 </b><b style="color:black"> 流 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> 建 </b><b style="color:black"> 設 </b><b style="color:black"> A </b><b style="color:black"> 類 </b><b style="color:black"> 高 </b><b style="color:black"> 校 </b><b style="color:black"> 」 </b><b style="color:black"> 和 </b><b style="color:black"> 原 </b><b style="color:black"> 「 </b><b style="color:black"> 985 </b><b style="color:black"> 工 </b><b style="color:black"> 程 </b><b style="color:black"> 」 </b><b style="color:black"> 、 </b><b style="color:black"> 原 </b><b style="color:black"> 「 </b><b style="color:black"> 211 </b><b style="color:black"> 工 </b><b style="color:black"> 程 </b><b style="color:black"> 」 </b><b style="color:black"> 重 </b><b style="color:black"> 點 </b><b style="color:black"> 建 </b><b style="color:black"> 設 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> ， </b><b style="color:black"> 具 </b><b style="color:black"> 有 </b><b style="color:black"> 人 </b><b style="color:black"> 文 </b><b style="color:black"> 社 </b><b style="color:black"> 會 </b><b style="color:black"> 科 </b><b style="color:black"> 學 </b><b style="color:black"> 、 </b><b style="color:black"> 醫 </b><b style="color:black"> 科 </b><b style="color:black"> 和 </b><b style="color:black"> 理 </b><b style="color:black"> 工 </b><b style="color:black"> 多 </b><b style="color:black"> 學 </b><b style="color:black"> 科 </b><b style="color:black"> 厚 </b><b style="color:black"> 實 </b><b style="color:black"> 基 </b><b style="color:black"> 礎 </b><b style="color:black"> ， </b><b style="color:black"> 被 </b><b style="color:black"> 譽 </b><b style="color:black"> 爲 </b><b style="color:black"> 「 </b><b style="color:green;font-style:bold"> 華 </b><b style="color:green;font-style:bold"> 南 </b><b style="color:black"> 第 </b><b style="color:black"> 一 </b><b style="color:black"> 學 </b><b style="color:black"> 府 </b><b style="color:black"> 」 </b><b style="color:orange;font-style:bold"> 中 </b><b style="color:orange;font-style:bold"> 山 </b><b style="color:orange;font-style:bold"> 大 </b><b style="color:orange;font-style:bold"> 學 </b><b style="color:black"> 在 </b><b style="color:black"> 2018 </b><b style="color:black"> 年 </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> 學 </b><b style="color:black"> 術 </b><b style="color:black"> 排 </b><b style="color:black"> 名 </b><b style="color:black"> 中 </b><b style="color:black"> ， </b><b style="color:black"> 位 </b><b style="color:black"> 列 </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 國 </b><b style="color:green;font-style:bold"> 大 </b><b style="color:green;font-style:bold"> 陸 </b><b style="color:black"> 第 </b><b style="color:black"> 4 </b><b style="color:black"> - </b><b style="color:black"> 6 </b><b style="color:black"> 名 </b><b style="color:black"> ， </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 第 </b><b style="color:black"> 101 </b><b style="color:black"> - </b><b style="color:black"> 150 </b><b style="color:black"> 名 </b><b style="color:black"> [ </b><b style="color:black"> 1 </b><b style="color:black"> ] </b><b style="color:black"> 在 </b><b style="color:black"> 2019 </b><b style="color:black"> 年 </b><b style="color:orange;font-style:bold"> Q </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> 排 </b><b style="color:black"> 名 </b><b style="color:black"> [ </b><b style="color:black"> 2 </b><b style="color:black"> ] </b><b style="color:black"> 、 </b><b style="color:black"> 2019 </b><b style="color:black"> 年 </b><b style="color:orange;font-style:bold"> 泰 </b><b style="color:orange;font-style:bold"> 晤 </b><b style="color:orange;font-style:bold"> 士 </b><b style="color:black"> 高 </b><b style="color:black"> 等 </b><b style="color:black"> 教 </b><b style="color:black"> 育 </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> 排 </b><b style="color:black"> 名 </b><b style="color:black"> 和 </b><b style="color:black"> 2020 </b><b style="color:black"> 年 </b><b style="color:orange;font-style:bold"> U </b><b style="color:orange;font-style:bold"> . </b><b style="color:orange;font-style:bold"> S </b><b style="color:orange;font-style:bold"> . </b><b style="color:orange;font-style:bold"> NEWS </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 大 </b><b style="color:black"> 學 </b><b style="color:black"> 排 </b><b style="color:black"> 名 </b><b style="color:black"> 中 </b><b style="color:black"> ， </b><b style="color:black"> 均 </b><b style="color:black"> 位 </b><b style="color:black"> 列 </b><b style="color:green;font-style:bold"> 中 </b><b style="color:green;font-style:bold"> 國 </b><b style="color:green;font-style:bold"> 大 </b><b style="color:green;font-style:bold"> 陸 </b><b style="color:black"> 第 </b><b style="color:black"> 8 </b><b style="color:black"> 名 </b><b style="color:black"> ， </b><b style="color:black"> 並 </b><b style="color:black"> 分 </b><b style="color:black"> 別 </b><b style="color:black"> 位 </b><b style="color:black"> 列 </b><b style="color:black"> 世 </b><b style="color:black"> 界 </b><b style="color:black"> 第 </b><b style="color:black"> 295 </b><b style="color:black"> 名 </b><b style="color:black"> 、 </b><b style="color:black"> 301 </b><b style="color:black"> - </b><b style="color:black"> 350 </b><b style="color:black"> 名 </b><b style="color:black"> 與 </b><b style="color:black"> 208 </b><b style="color:black"> 名 </b><b style="color:black"> ， </b><b style="color:black"> 近 </b><b style="color:black"> 年 </b><b style="color:black"> 排 </b><b style="color:black"> 名 </b><b style="color:black"> 提 </b><b style="color:black"> 升 </b><b style="color:black"> 迅 </b><b style="color:black"> 猛 </b></p>
<ul>
<li>这一次混杂了中英文， 简繁， 缩写等元素， 整体识别率不错， 人名， 地名， 组织都可以识别。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>BERT在多语言方面有着天然的优势， 只是训练时间成本有点大， 另外forward的性能很一般。</p>
<p>期待BERT能进一步优化， 而不是简单的堆砌数据， 让老百姓也能玩得起transformers。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/09/09/BERT_NER_CN_EN/" data-id="ckev50nuf0000rkuo4tp8e6e6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NER/" rel="tag">NER</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag">自然语言处理</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-微软认知服务(Cognitive Services) 实体识别" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/" class="article-date">
  <time datetime="2020-08-27T05:34:57.826Z" itemprop="datePublished">2020-08-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/technology/">technology</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">微软认知服务</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>微软Azure推出的一系列<a target="_blank" rel="noopener" href="https://azure.microsoft.com/zh-cn/services/cognitive-services/">认知服务</a>, 其中文本分析功能包括实体识别(NER),情感分析,关键短语抽取, 语言检测等一系列功能。</p>
<p>这里简单测试一下其相关功能。</p>
<p>相关服务：</p>
<ul>
<li>NER： <a target="_blank" rel="noopener" href="https://docs.microsoft.com/zh-cn/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-entity-linking?tabs=version-3">命名实体识别</a> </li>
<li>语言检测:  检测文本的语言</li>
<li>关键短语提取： Key-phrase extraction</li>
<li>情感分析：sentiment analysis</li>
</ul>
<h1 id="注册微软Azure服务"><a href="#注册微软Azure服务" class="headerlink" title="注册微软Azure服务"></a>注册微软Azure服务</h1><p>这里有微软账号的也需要开通Azure服务，初级使用者可以免费使用部分服务：<a target="_blank" rel="noopener" href="https://azure.microsoft.com/zh-cn/free/">注册入口</a></p>
<p>注册完毕登录后， 通过<a target="_blank" rel="noopener" href="https://portal.azure.com/#home">门户</a> 进入认知服务：</p>
<img src="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/0.png" class="">


<h1 id="获取API-Key-amp-End-Point"><a href="#获取API-Key-amp-End-Point" class="headerlink" title="获取API Key &amp; End Point"></a>获取API Key &amp; End Point</h1><h2 id="创建文本分析的资源（Text-Analysis-Resource"><a href="#创建文本分析的资源（Text-Analysis-Resource" class="headerlink" title="创建文本分析的资源（Text  Analysis Resource)"></a>创建文本分析的资源（Text  Analysis Resource)</h2><p>在认知服务面板点击Add按钮，在market place面板搜索text analysis后，选择创建（Create）： </p>
<img src="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/1.png" class="">

<p>后续步骤按部就班填完资料， 收费计划选择免费的F0即可， 微软提供一个月5000免费额度。</p>
<h2 id="获取API-Key-和-End-Point"><a href="#获取API-Key-和-End-Point" class="headerlink" title="获取API Key 和 End Point"></a>获取API Key 和 End Point</h2><p>点击创建完的resource，进入资源面板后选择Keys and Endpoint:</p>
<img src="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2.png" class="">

<p>一共有2个Key， 任意一个都可以使用， 后续直接调用Endpoint+service即可使用文本分析各个功能。</p>
<h1 id="测试服务"><a href="#测试服务" class="headerlink" title="测试服务"></a>测试服务</h1><h2 id="语言检测：language-detect"><a href="#语言检测：language-detect" class="headerlink" title="语言检测：language detect"></a>语言检测：language detect</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># key &amp; endpoint</span></span><br><span class="line">key1=<span class="string">&quot;*****************************&quot;</span></span><br><span class="line">endpoint=<span class="string">&quot;https://xxxxx.cognitiveservices.azure.com/&quot;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># key &amp; endpoint</span></span><br><span class="line">key1=<span class="string">&quot;842408cbfac54f5d9d54e6d82096aa75&quot;</span></span><br><span class="line">endpoint=<span class="string">&quot;https://upsbrief.cognitiveservices.azure.com/&quot;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># pprint is used to format the JSON response</span></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">subscription_key = key1</span><br><span class="line">language_api_url = endpoint + <span class="string">&quot;/text/analytics/v3.0/languages&quot;</span></span><br><span class="line">documents = &#123;<span class="string">&quot;documents&quot;</span>: [</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;1&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">&quot;This is a document written in English.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;2&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">&quot;Este es un document escrito en Español.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;3&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">&quot;这是一个用中文写的文件&quot;</span>&#125;</span><br><span class="line">]&#125;</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&quot;Ocp-Apim-Subscription-Key&quot;</span>: subscription_key&#125;</span><br><span class="line">response = requests.post(language_api_url, headers=headers, json=documents)</span><br><span class="line">languages = response.json()</span><br><span class="line">pprint(languages)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;documents&#39;: [&#123;&#39;detectedLanguage&#39;: &#123;&#39;confidenceScore&#39;: 1.0,
                                     &#39;iso6391Name&#39;: &#39;en&#39;,
                                     &#39;name&#39;: &#39;English&#39;&#125;,
                &#39;id&#39;: &#39;1&#39;,
                &#39;warnings&#39;: []&#125;,
               &#123;&#39;detectedLanguage&#39;: &#123;&#39;confidenceScore&#39;: 1.0,
                                     &#39;iso6391Name&#39;: &#39;es&#39;,
                                     &#39;name&#39;: &#39;Spanish&#39;&#125;,
                &#39;id&#39;: &#39;2&#39;,
                &#39;warnings&#39;: []&#125;,
               &#123;&#39;detectedLanguage&#39;: &#123;&#39;confidenceScore&#39;: 1.0,
                                     &#39;iso6391Name&#39;: &#39;zh_chs&#39;,
                                     &#39;name&#39;: &#39;Chinese_Simplified&#39;&#125;,
                &#39;id&#39;: &#39;3&#39;,
                &#39;warnings&#39;: []&#125;],
 &#39;errors&#39;: [],
 &#39;modelVersion&#39;: &#39;2020-07-01&#39;&#125;</code></pre>
<p>从结果来看， 这语言检测对大公司来说就是小菜一碟， 没啥挑战性。</p>
<p>下面试试其他服务： </p>
<h2 id="NER："><a href="#NER：" class="headerlink" title="NER："></a>NER：</h2><p>实体识别是个经典的文本分析应用，目前很多算法模型都能做到85%~95%的准确率（看分类的数目和语言）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">entities_url = endpoint + <span class="string">&quot;/text/analytics/v3.1-preview.1/entities/recognition/pii&quot;</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">WeChat Official Accounts appear in the chat list of WeChat along with all your other contact messages. </span></span><br><span class="line"><span class="string">Users can open the official account to access customized information through the bottom menu interface.</span></span><br><span class="line"><span class="string">Push notifications are messages that pop up on the user’s chat and show up </span></span><br><span class="line"><span class="string">at any time when the official account sends a message.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">documents = &#123;<span class="string">&quot;documents&quot;</span>: [</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;1&quot;</span>,<span class="string">&quot;language&quot;</span>:<span class="string">&quot;en&quot;</span>, <span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line">]&#125;</span><br><span class="line">headers = &#123;<span class="string">&quot;Ocp-Apim-Subscription-Key&quot;</span>: subscription_key&#125;</span><br><span class="line">response = requests.post(entities_url, headers=headers, json=documents)</span><br><span class="line">entities = response.json()</span><br><span class="line">pprint(entities)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;documents&#39;: [&#123;&#39;entities&#39;: [&#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.28,
                              &#39;length&#39;: 6,
                              &#39;offset&#39;: 53,
                              &#39;text&#39;: &#39;WeChat&#39;&#125;],
                &#39;id&#39;: &#39;1&#39;,
                &#39;warnings&#39;: []&#125;],
 &#39;errors&#39;: [],
 &#39;modelVersion&#39;: &#39;2020-07-01&#39;&#125;</code></pre>
<p>它把WeChat识别成了Person（人名），从这结果看来，微软的NER算法并不是很理想， 或者其背后的预料训练不够充分， 要知道NER对语料要求也很高的。</p>
<p>也有可能对于中文的翻译的文本不熟悉， 下面换成wiki的apple简介， 摘取两段试试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">entities_url = endpoint + <span class="string">&quot;/text/analytics/v3.1-preview.1/entities/recognition/pii&quot;</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Apple Inc. is an American multinational technology company headquartered in Cupertino, California,</span></span><br><span class="line"><span class="string">that designs, develops, and sells consumer electronics, </span></span><br><span class="line"><span class="string">computer software, and online services. </span></span><br><span class="line"><span class="string">It is considered one of the Big Tech technology companies, </span></span><br><span class="line"><span class="string">alongside Amazon, Google, Microsoft, and Facebook. </span></span><br><span class="line"><span class="string">Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976 to develop and sell</span></span><br><span class="line"><span class="string">Wozniak&#x27;s Apple I personal computer, though Wayne sold his share back within 12 days. &#x27;&#x27;&#x27;</span></span><br><span class="line">documents = &#123;<span class="string">&quot;documents&quot;</span>: [</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;1&quot;</span>,<span class="string">&quot;language&quot;</span>:<span class="string">&quot;en&quot;</span>, <span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line">]&#125;</span><br><span class="line">headers = &#123;<span class="string">&quot;Ocp-Apim-Subscription-Key&quot;</span>: subscription_key&#125;</span><br><span class="line">response = requests.post(entities_url, headers=headers, json=documents)</span><br><span class="line">entities = response.json()</span><br><span class="line">pprint(entities)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;documents&#39;: [&#123;&#39;entities&#39;: [&#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.92,
                              &#39;length&#39;: 10,
                              &#39;offset&#39;: 1,
                              &#39;text&#39;: &#39;Apple Inc.&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.71,
                              &#39;length&#39;: 8,
                              &#39;offset&#39;: 226,
                              &#39;text&#39;: &#39;Big Tech&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.91,
                              &#39;length&#39;: 6,
                              &#39;offset&#39;: 268,
                              &#39;text&#39;: &#39;Amazon&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.93,
                              &#39;length&#39;: 6,
                              &#39;offset&#39;: 276,
                              &#39;text&#39;: &#39;Google&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.94,
                              &#39;length&#39;: 9,
                              &#39;offset&#39;: 284,
                              &#39;text&#39;: &#39;Microsoft&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.91,
                              &#39;length&#39;: 16,
                              &#39;offset&#39;: 299,
                              &#39;text&#39;: &#39;Facebook.、\nApple&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.77,
                              &#39;length&#39;: 10,
                              &#39;offset&#39;: 331,
                              &#39;text&#39;: &#39;Steve Jobs&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.9,
                              &#39;length&#39;: 13,
                              &#39;offset&#39;: 343,
                              &#39;text&#39;: &#39;Steve Wozniak&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.85,
                              &#39;length&#39;: 12,
                              &#39;offset&#39;: 362,
                              &#39;text&#39;: &#39;Ronald Wayne&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.58,
                              &#39;length&#39;: 7,
                              &#39;offset&#39;: 409,
                              &#39;text&#39;: &#39;Wozniak&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Organization&#39;,
                              &#39;confidenceScore&#39;: 0.44,
                              &#39;length&#39;: 5,
                              &#39;offset&#39;: 419,
                              &#39;text&#39;: &#39;Apple&#39;&#125;,
                             &#123;&#39;category&#39;: &#39;Person&#39;,
                              &#39;confidenceScore&#39;: 0.83,
                              &#39;length&#39;: 5,
                              &#39;offset&#39;: 453,
                              &#39;text&#39;: &#39;Wayne&#39;&#125;],
                &#39;id&#39;: &#39;1&#39;,
                &#39;warnings&#39;: []&#125;],
 &#39;errors&#39;: [],
 &#39;modelVersion&#39;: &#39;2020-07-01&#39;&#125;</code></pre>
<p>这次对于Person和Organization的识别还算准确， 但还是暴露了几个问题： </p>
<ul>
<li>对于地点貌似直接省略了，比如Cupertino, California， 很多NER服务会直接给出Place或者Location的分类。</li>
<li>文本处理不够干净， 比如{‘category’: ‘Organization’,…’text’: ‘Facebook.、\nApple’}, 当然清理文本不应该是NER处理的事情， 只不过作为API最基本的参数清理感觉还是很有必要的， 特别是换行空格之类的规范化， 对于NER的各种坑应该也是一种预防手段。</li>
<li>分类属于最基本的几种， 没有深入细分。</li>
</ul>
<p>对于NER的英文测试， 只能说微软的算法表现非常一般。</p>
<p>下面测试中文：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">entities_url = endpoint + <span class="string">&quot;/text/analytics/v3.1-preview.1/entities/recognition/pii&quot;</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">微软 表示在 重大更新 之后并非所有人都清楚具体在哪些方面有所改进，甚至有很大一部分人不清楚如何启用新功能和改进。</span></span><br><span class="line"><span class="string">这意味着在系统更新之后引入的新功能，可能无法给用户带来真正的好处。为此，微软希望进行改变。&#x27;&#x27;&#x27;</span></span><br><span class="line">documents = &#123;<span class="string">&quot;documents&quot;</span>: [</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="string">&quot;1&quot;</span>,<span class="string">&quot;language&quot;</span>:<span class="string">&quot;zh_chs&quot;</span>, <span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line">]&#125;</span><br><span class="line">headers = &#123;<span class="string">&quot;Ocp-Apim-Subscription-Key&quot;</span>: subscription_key&#125;</span><br><span class="line">response = requests.post(entities_url, headers=headers, json=documents)</span><br><span class="line">entities = response.json()</span><br><span class="line">pprint(entities)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;documents&#39;: [],
 &#39;errors&#39;: [&#123;&#39;error&#39;: &#123;&#39;code&#39;: &#39;InvalidArgument&#39;,
                       &#39;innererror&#39;: &#123;&#39;code&#39;: &#39;UnsupportedLanguageCode&#39;,
                                      &#39;message&#39;: &#39;Invalid language code. &#39;
                                                 &#39;Supported languages: en&#39;&#125;,
                       &#39;message&#39;: &#39;Invalid Language Code.&#39;&#125;,
             &#39;id&#39;: &#39;1&#39;&#125;],
 &#39;modelVersion&#39;: &#39;2020-07-01&#39;&#125;</code></pre>
<p>好吧， 微软认知服务的文本分析， NER功能直接不支持中文， 仅仅支持英文。</p>
<p>到了这里感觉无需进一步测试了，简单总结一下：</p>
<p>微软的文本分析模块算法，功能性能都非常一般。不过这一贯都是微软的策略， 无论微软研究院多么前瞻的技术， 在实际的产品中都会以最保守的方式呈现给用户。</p>
<p>归纳一下优缺点:</p>
<ul>
<li><p>优点：</p>
<ul>
<li>免费试用（5000额度一个月），为数不多能想到的优点</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>高级功能不支持多语言，感觉更像一款玩具而不是一个产品</li>
<li>部署稍微繁琐，各种创建资源</li>
<li>功能保守， 比如NER只有最基本的Person 和Organization (Location?). 不像很多基金的平台，提供二级甚至多级的分类</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/" data-id="ckev4vgid0001k4uoehpwa2m9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NER/" rel="tag">NER</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E8%BD%AFAzure/" rel="tag">微软Azure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag">自然语言处理</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/technology/">technology</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NER/" rel="tag">NER</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E8%BD%AFAzure/" rel="tag">微软Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag">自然语言处理</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/BERT/" style="font-size: 10px;">BERT</a> <a href="/tags/NER/" style="font-size: 20px;">NER</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/%E5%BE%AE%E8%BD%AFAzure/" style="font-size: 10px;">微软Azure</a> <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" style="font-size: 20px;">自然语言处理</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/09/09/BERT_NER_CN_EN/">基于BERT多语言的NER应用</a>
          </li>
        
          <li>
            <a href="/2020/08/27/%E5%BE%AE%E8%BD%AF%E8%AE%A4%E7%9F%A5%E6%9C%8D%E5%8A%A1(Cognitive%20Services)%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">微软认知服务</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 vincent leung<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/contact-me" class="mobile-nav-link">Contact</a>
  
    <a href="/donate-me" class="mobile-nav-link">Donate</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>